{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e0f24-c9fb-42c0-9643-31e11da9e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431412d7-b7c3-4a5e-82de-8c79d3da557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_keyword(keyword):\n",
    "    # Convert to lowercase\n",
    "    keyword = keyword.lower()\n",
    "    # Remove parentheses and their contents\n",
    "    keyword = re.sub(r'\\s*\\([^)]*\\)', '', keyword)\n",
    "    # Tokenize words\n",
    "    words = nltk.word_tokenize(keyword)\n",
    "    \n",
    "    # Initialize stemmer and lemmatizer\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Apply stemming and lemmatization\n",
    "    processed_words = [lemmatizer.lemmatize(stemmer.stem(word)) for word in words]\n",
    "    # Return the list of processed keywords\n",
    "    return processed_words\n",
    "\n",
    "def extract_compound_keywords_from_json(folder_path):\n",
    "    compound_keywords_dict = {}\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                \n",
    "                # Extract keywords from the JSON structure\n",
    "                keywords_data = data.get('full-text-retrieval-response', {}).get('coredata', {}).get('dcterms:subject', [])\n",
    "                keywords = [kw['$'] for kw in keywords_data if '$' in kw]\n",
    "                \n",
    "                for keyword in keywords:\n",
    "                    processed_words = preprocess_keyword(keyword)\n",
    "                    if len(processed_words) > 1:\n",
    "                        compound_keyword = '_'.join(processed_words)\n",
    "                        normal_keyword = ' '.join(processed_words)\n",
    "                        compound_keywords_dict[normal_keyword] = compound_keyword\n",
    "                    \n",
    "    return compound_keywords_dict\n",
    "\n",
    "def save_dict_as_py(dict_obj, output_file):\n",
    "    # Convert dictionary to string and add import statement\n",
    "    dict_content = f\"compound_keywords = {dict_obj}\\n\"\n",
    "    # Write to a .py file\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(dict_content)\n",
    "\n",
    "folder_path = 'C:/Users/wenha/OneDrive - University College London/Desktop/first_paper_code/downloaded_articles'\n",
    "compound_keywords = extract_compound_keywords_from_json(folder_path)\n",
    "\n",
    "# Save dictionary to a .py file\n",
    "output_file = 'compound_keywords.py'\n",
    "save_dict_as_py(compound_keywords, output_file)\n",
    "print(f\"Dictionary has been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9ff341-701a-4a62-82ee-e75d3f154820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
